
%%main findings summary


In Fig.~\ref{figure_jobmakespan} we can see that the static allocation
has the highest makespan, the rationale behind this, is that during
the peak usage in the sample workload, there will be jobs that will
have to wait a relatively long time due to the static nature of the
policy and due to the almost equally sized jobs and
\textsc{fcfs}-policy - the job which is added when the queue is largest
will also have the largest makespan.

%% tradeoffs -- added by Lipu Fei, please check
The tradeoff table \ref{table_speedupcost} shows that our
\policysimpleelastic{} policy achieves a better speedup-cost tradeoff
with its \emph{threshold} set to 5. However, our workloads for testing
are relatively simple, so it could get worse when the system is more
overloaded.



%% drawbacks of SimpleElastic provisioning (VM waste)
%% -- added by Lipu Fei, please check

What is interesting to see is that the \SEzero{} has higher makespan
for the 20ms mean interval, but not for the 10ms and 30ms mean
interval, This can be explained as mentioned
in \ref{section_vm_performance} that an obvious drawback of
our \policysimpleelastic{} provisioning policy is that it can waste
allocated VMs.  Especially for \SEzero{}, in the
workload \textsc{wl-10} it has a significant overhead. This is mainly
caused by the immediate termination of VMs when no pending job
available. An improvement can be made by adding an \emph{aggregate
idle time}, indicating how long a VM has been idle since (1) it was
created or (2) the last time it finished a job, and also setting up a
new threshold. When the pending job queue is empty, the provisioning
policy updates all VMs' \emph{aggregate idle time} and terminates a VM
with its \emph{aggregate idle time} higher than the threshold.  A more
structural improvement would be to see if the boot time of the VM's OS
can be shortened. This would probably positively influence the results
a lot, however making such adjustments to the provided IaaS in
question---OpenNebula on \textsc{das-4}---is not trivial due to
lacking permissions for such adjustments. However we could test with
artificial boot-times by allocating the maximum amount of VMs in
advance and then imitate the availability of the VMs after the desired
amount of time we'd like to test. That way we can see how much there
is to gain by making the boot sequence more efficient. Also the
pausing and resuming of VMs could be implemented which could cause for
a more simple implementation.

A different method of lowering the waiting time for the jobs due to
free VM scarcity would be to follow the strategies outlined
by \cite{Shen:2011:CER:2038916.2038921}, they proposed a prediction
algorithm which can be used in future work to create new VMs in a more
timely manner so the job waiting time will be reduced.

%% Some other discussions
%% -- added by Lipu Fei, please check
Besides the above, in reality, the video conversion jobs submitted by
users are probably larger files sizing more than 4GB, which is the
conventional size of a \textsc{h.264} movie. If the time it takes for
a video to convert goes linearly with the size of the input file, then
a 4GB will probably take more than 40 minutes to finish with our
current VM setup. An enhancement to this would be to create a
decentralized system that works in the following way: when a job
arrives, the system assigns it to a VM. The VM first checks the size
of the input, and it divides the input file into two (or more)
equal-sized parts if the original size is too large.  The smaller
parts are then sent to other VMs, who process the input in the same
way. When the size is small enough, a VM will convert the input. This
VM can be considered a leaf node in the tree of VMs. All parent nodes
will wait for their child nodes to finish and upload the results, and
then merge them in order. Finally, the root node will get all the
merged results. We think this is doable, for \textsc{FFmpeg} is very
efficient in concatenating two video files. Through this method not
only would our application scale in the number of jobs, but also scale
in the size of individual jobs.

If we take our workloads to be representative we can make
extrapolations, we calculate the numbers in Table
\ref{table_extrapolatedchargedcosts}. The numbers have been calculated by
taking the costs of the workloads extrapolated over their workspan
time, i.e. the costs which would have incurred if the tests were run
repeatedly for the designated extrapolated time period.


%% about future work, may be put into another paragraph
%% -- added by Lipu Fei, please check
So for future work, we are considering the following options:
\begin{enumerate}
\item Carrying out a benchmark test on larger input files to get the
  growth of job's running time against input size.

\item Improving the current provisioning policy with our proposed
  suggestion using threshold after which VMs can be released.
\item Improving boot times through more efficient OS boot-time and/or
  make use of pausing/resuming VMs.

\item Create a decentralize system that uses divide-and-conquer
  mechanism to solve large inputs.

\end{enumerate}



%%recommendation

%% extrapolation


\begin{table}
\caption{Extrapolated Charged-costs}
\label{table_extrapolatedchargedcosts}
\centering
\begin{tabular}{|l|p{1.5cm}|p{1.5cm}|p{1.5cm}|}
\hline
Workload & \multicolumn{3}{|c|}{Extrapolated with Workspan Runtime}\\
\cline{2-4}
 & STATIC & SE-0 & SE-5 \\
\hline
\texttt{wl-10} &
1d(\$19.22) 1m(\$576.63) 1y(\$7015.60) &
1d(\$45.93) 1m(\$1377.83) 1y(\$16763.56) &
1d(\$52.05) 1m(\$1561,48) 1y(\$18998.11)\\
\hline
\texttt{wl-20} &
1d(\$19.13) 1m(\$574.00) 1y(\$6983.71) &
1d(\$30.99) 1m(\$929.65) 1y(\$11310.76) &
1d(\$21.63) 1m(\$649.00) 1y(\$7896.19) \\
\hline
\texttt{wl-30} &
1d(\$19.19) 1m(\$575.66) 1y(\$7003.89) &
1d(\$19.67) 1m(\$590.09) 1y(\$7179.4) &
1d(\$19.20) 1m(\$576.11) 1y(\$7009.37)\\
\hline
\end{tabular}
\end{table}
